{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "090e639b",
   "metadata": {},
   "source": [
    "# Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce296b75",
   "metadata": {},
   "source": [
    "# Business Understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8507a8d8",
   "metadata": {},
   "source": [
    "# Data Understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b9536b9",
   "metadata": {},
   "source": [
    "## Limitations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9906e746",
   "metadata": {},
   "source": [
    "# Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb613ea7",
   "metadata": {},
   "source": [
    "## Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2428ba3",
   "metadata": {},
   "source": [
    "Before we dive into modeling, we will have to make sure the data is ready for our neural networks to process. The process for preparing image data has a few extra steps, as we need to essentially create a slightly augmented and formatted reproduction of our original images before we feed them into the network. The generation and augmentation process involves editing things like the size of the image (these models generally need uniform sizing). Optionally, we can add further augmentations such as random changes in zoom, skewing the images one way or the other, and even flipping images vertically or horizontally. This can add some more noise to the training data, sometimes improving outcomes. Since this is medical data, however, I want to refrain from making too many changes.\n",
    "\n",
    "Another challenge facing us is the size of our validation set. While there are over 5000 images in our train set, our validation set is only 16 images. Since we are using backpropagation in our models, having inaccurate or otherwise wonky results on the validation set can hinder the model's self-improvement. We will want to draw a far larger sample for our validation data. My solution is to just split the large training set into 85% train and 15% validation.\n",
    "\n",
    "Finally, we must also address the fairly-large class imbalance in the training data. While such imbalances are common in real-world data, it would be prefarable to even this dataset out a little bit so our model can't just get away with guessing one class over and over. We can do this in myriad ways, but I have chosen to experiment with downsampling the majority class and applying different class weights during training to artificially increase the importance of the minority class.\n",
    "\n",
    "Below, I will go through a brief exploratory process before moving on to addressing our preprocessing challenges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0c4c1bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import relevant libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import tensorflow\n",
    "import os, shutil\n",
    "from shutil import copyfile\n",
    "import random\n",
    "import tensorflow as tf\n",
    "import scikeras\n",
    "import seaborn as sns\n",
    "import sympy\n",
    "from sympy import symbols, Eq, solve\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from tensorflow.keras import layers, models\n",
    "from PIL import Image\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Conv2D, GlobalAveragePooling2D, MaxPooling2D\n",
    "from tensorflow.keras.layers import Input, Flatten, Dense, Dropout, BatchNormalization, Activation\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.metrics import classification_report, accuracy_score, f1_score, precision_score, recall_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from skimage.segmentation import mark_boundaries\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "import scipy\n",
    "from scipy import ndimage\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from keras import regularizers\n",
    "from lime import lime_image\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb7a47a3",
   "metadata": {},
   "source": [
    "Since we can't just throw this data into pandas like we do for text or tabular data, we'll need to define some system paths so we can more easily navigate to and from image directories during preprocessing, training, and testing. Let's define some pathways below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08938467",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = '/Users/adampell/Documents/Flatiron/phase-4/phase-4-project/data/chest_xray/train'\n",
    "val_dir = '/Users/adampell/Documents/Flatiron/phase-4/phase-4-project/data/chest_xray/val'\n",
    "test_dir = '/Users/adampell/Documents/Flatiron/phase-4/phase-4-project/data/chest_xray/test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0921fb63",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_normal_dir = '/Users/adampell/Documents/Flatiron/phase-4/phase-4-project/data/chest_xray/train/NORMAL'\n",
    "train_pneumonia_dir = '/Users/adampell/Documents/Flatiron/phase-4/phase-4-project/data/chest_xray/train/PNEUMONIA'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d06b34b",
   "metadata": {},
   "source": [
    "Now that we've defined those pathways, let's create some quick functions to see what these images actually look like. Notice that, when we're loading these images, we actually have to open the file, load the image into a tensor, and then turn that tensor back into an image. Below, we can see visualization functions for both the normal and pneumonia images. The functions will return the index of any image the user inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "203a715a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_normal_image(number):\n",
    "    normal_class_dir = os.path.join(train_dir, 'NORMAL')\n",
    "    normal_train_file_list = os.listdir(normal_class_dir)\n",
    "    normal_image_path = os.path.join(normal_class_dir, normal_train_file_list[number])\n",
    "    \n",
    "    image = Image.open(normal_image_path)\n",
    "    image_array = np.array(image)\n",
    "\n",
    "    # Display the image\n",
    "    plt.imshow(image_array, cmap='gray')\n",
    "    plt.show()\n",
    "    print(image.size)\n",
    "    \n",
    "    \n",
    "get_normal_image(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc7d5b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pneumonia_image(number):\n",
    "    pneumonia_class_dir = os.path.join(train_dir, 'PNEUMONIA')\n",
    "    pneumonia_train_file_list = os.listdir(pneumonia_class_dir)\n",
    "    pneumonia_image_path = os.path.join(pneumonia_class_dir, pneumonia_train_file_list[number])\n",
    "    \n",
    "    image = Image.open(pneumonia_image_path)\n",
    "    image_array = np.array(image)\n",
    "\n",
    "    # Display the image\n",
    "    plt.imshow(image_array, cmap='gray')\n",
    "    plt.show()\n",
    "    print(image.size)\n",
    "    \n",
    "    \n",
    "get_pneumonia_image(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05d296fb",
   "metadata": {},
   "source": [
    "To the untrained eye, it is difficult to see which lungs are infected and which are not. We will see if we can build a model to pick up on the telltale symptom of pneumonia: clouding of the lungs.\n",
    "\n",
    "Let's get a better look at the class distribution of the train, validation, and test datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8943950",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_class_counts(directory):\n",
    "    normal_class_dir = os.path.join(directory, 'NORMAL')\n",
    "    normal_list = os.listdir(normal_class_dir)\n",
    "\n",
    "    pneumonia_class_dir = os.path.join(directory, 'PNEUMONIA')\n",
    "    pneumonia_list = os.listdir(pneumonia_class_dir)\n",
    "    \n",
    "    print(len(normal_list))\n",
    "    print(len(pneumonia_list))\n",
    "\n",
    "    print('Normal %: ', len(normal_list)/(len(normal_list) + len(pneumonia_list)))\n",
    "    print('Pneumonia %: ', len(pneumonia_list)/(len(normal_list) + len(pneumonia_list)))\n",
    "\n",
    "print('Training Class Counts:')\n",
    "get_class_counts(train_dir)\n",
    "print('')\n",
    "print('Validation Class Counts:')\n",
    "get_class_counts(val_dir)\n",
    "print('')\n",
    "print('Test Class Counts:')\n",
    "get_class_counts(test_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74fe0c25",
   "metadata": {},
   "source": [
    "As mentioned above, we see a fairly large class disparity in our training set, and, while our validation data is evenly distributed, there are only 16 images total. Let's create some data generators so we can experiment using different class distributions.\n",
    "\n",
    "In this code, we are scaling the images down to values between 0 and 1 as opposed to their normal values between 0 and 256 as RGB images. Next, we are setting the directory the images are to be taken from and dictating the size we want the images to be when they are fed into the model. 512 seems to be the sweet spot between maintaining image quality and not bogging down training time with massive processing volume."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "880fb1ce",
   "metadata": {},
   "source": [
    "The block below creates a larger validation set by slicing some off images off a shuffled training set. Since only 16 images were in the original validation directory, we are not losing much data by doing it this way. These will serve as our base generators. Notice that our test generator still stands on its own, as it contains an adequate sample size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bd93bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an ImageDataGenerator with a validation split\n",
    "datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    validation_split=0.15)\n",
    "\n",
    "# Create generators for training and validation\n",
    "train_generator = datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(512, 512),  # The target size for our images\n",
    "    batch_size=64,  # The batch size\n",
    "    class_mode='binary',\n",
    "    subset='training',  # Set the subset of data to training\n",
    "    shuffle=True)\n",
    "\n",
    "validation_generator = datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(512, 512),\n",
    "    batch_size=64,\n",
    "    class_mode='binary',\n",
    "    subset='validation',  # Set the subset of data to validation\n",
    "    shuffle=True)\n",
    "\n",
    "test_generator = ImageDataGenerator(rescale=1./255).flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(512,512),\n",
    "    batch_size=64, class_mode='binary', shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "691db6a0",
   "metadata": {},
   "source": [
    "Let's take a look at a sample image that comes out of this generator. You might notice that, at 512x512, the quality may be slightly worse than our crisp images with pixel counts in the thousands. Nevertheless, though, it still looks good enough that small aberrations would be visible to the model. In other words, it will still be able to pick up on small nuances and indicators in each image despite the slight decrease in quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "480771c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "images, labels = next(train_generator)\n",
    "\n",
    "# Extract a single image from the batch\n",
    "image = images[0]\n",
    "\n",
    "# Plot the image\n",
    "plt.imshow(image)\n",
    "plt.axis('off')  # Hide the axes for better visualization\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea3518ea",
   "metadata": {},
   "source": [
    "Now that we've visualized our data and created our generators, we can move onto building some neural networks!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e0ed104",
   "metadata": {},
   "source": [
    "## Preliminary Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a176e8d7",
   "metadata": {},
   "source": [
    "This is where our iterative modeling process begins. Each model will be increasingly complex, with complexity in this case being defined by how many trainable parameters we are dealing with. Additionally, we will be adding optimization techniques such as dropout layers to prevent overfitting. Our later models will be convolutional neural networks, which feature convoluting and pooling layers that reduce the dimensionality of the image data before feeding into normal dense neuron layers. Finally, we will implement transfer learning using MobileNet V2, a CNN with 53 layers that has been trained on over a million images of all kinds. It is often the case that using these models to fit our dataset will yield sueprior results to our base training alone.\n",
    "\n",
    "Our target metric will be **accuracy**. However, given the nature of the field we are researching, we will also have to be mindful of false positives and false negatives, as high rates of either could have cascading real-world consequences. We will be able to visualize model performance in several ways. These include graphing model loss and performance gains over training epochs. As the models get more complex, it may also be beneficial to visualize the model architectures and activation functions we are using. \n",
    "\n",
    "We will begin below with a baseline, vanilla model with only a couple hidden layers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3a9390f",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_model = Sequential()\n",
    "\n",
    "baseline_model.add(Flatten(input_shape=(512, 512, 3)))\n",
    "baseline_model.add(Dense(256, activation='relu'))\n",
    "baseline_model.add(Dense(128, activation='relu'))\n",
    "baseline_model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "baseline_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "baseline_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed1f8f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights_baseline = {0 : 2, 1 : 1}\n",
    "\n",
    "history_baseline = baseline_model.fit(\n",
    "    train_generator, \n",
    "    epochs=20, \n",
    "    batch_size=64, \n",
    "    validation_data=validation_generator,\n",
    "    class_weight=class_weights_baseline,\n",
    "    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31f5850d",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_labels_baseline = test_generator.classes\n",
    "predicted_probabilities_baseline = baseline_model.predict(test_generator)\n",
    "predicted_labels_baseline = predicted_probabilities_baseline > 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "019601dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_report = classification_report(true_labels_vanilla, predicted_labels_baseline, target_names=['Normal', 'Pneumonia'])\n",
    "print(baseline_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "639526bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_train_loss = history_baseline.history['loss']\n",
    "baseline_val_loss = history_baseline.history['val_loss']\n",
    "\n",
    "epoch_count = range(1, len(baseline_train_loss) + 1)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(epoch_count, baseline_train_loss)\n",
    "plt.plot(epoch_count, baseline_val_loss)\n",
    "plt.legend(['Training Loss', 'Validation Loss'])\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss Over Epochs')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e1eb260",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_mat = confusion_matrix(true_labels_baselien, predicted_labels_baseline)\n",
    "sns.heatmap(baseline_mat.T, square=True, annot=True, fmt='d', cbar=False, cmap='viridis',\n",
    "            xticklabels=['Negative', 'Positive'],\n",
    "            yticklabels=['Negative', 'Positive'])\n",
    "plt.xlabel('True Labels')\n",
    "plt.ylabel('Predicted Labels')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0607904c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dropout_model = Sequential()\n",
    "\n",
    "dropout_model.add(Flatten(input_shape=(512, 512, 3)))\n",
    "dropout_model.add(Dense(256, activation='leaky_relu'))\n",
    "dropout_model.add(Dropout(0.5))\n",
    "dropout_model.add(Dense(128, activation='leaky_relu'))\n",
    "dropout_model.add(Dropout(0.5))\n",
    "dropout_model.add(Dense(64, activation='leaky_relu'))\n",
    "dropout_model.add(Dropout(0.5))\n",
    "dropout_model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "dropout_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "dropout_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a42dc144",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, verbose=1, mode='min', restore_best_weights=True)\n",
    "\n",
    "class_weights_dropout = {0 : 1.9, 1 : 1}\n",
    "\n",
    "history_dropout = dropout_model.fit(\n",
    "    train_generator,\n",
    "    epochs=60,\n",
    "    batch_size=64,\n",
    "    validation_data=validation_generator,\n",
    "    callbacks=[early_stopping, model_checkpoint],\n",
    "    class_weight=class_weights_dropout,\n",
    "    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e8b466",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_labels_dropout = test_generator.classes\n",
    "predicted_probabilities_dropout = dropout_model.predict(test_generator)\n",
    "predicted_labels_dropout = predicted_probabilities_dropout > 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c665b0ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "dropout_report = classification_report(true_labels_dropout, predicted_labels_dropout, target_names=['Normal', 'Pneumonia'])\n",
    "print(dropout_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cd3652f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dropout_train_loss = history_dropout.history['loss']\n",
    "dropout_val_loss = history_dropout.history['val_loss']\n",
    "\n",
    "epoch_count = range(1, len(dropout_train_loss) + 1)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(epoch_count, dropout_train_loss)\n",
    "plt.plot(epoch_count, dropout_val_loss)\n",
    "plt.legend(['Training Loss', 'Validation Loss'])\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss Over Epochs')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "319c08b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dropout_mat = confusion_matrix(true_labels_vanilla, predicted_labels_dropout)\n",
    "sns.heatmap(dropout_mat.T, square=True, annot=True, fmt='d', cbar=False, cmap='viridis',\n",
    "            xticklabels=['Negative', 'Positive'],\n",
    "            yticklabels=['Negative', 'Positive'])\n",
    "plt.xlabel('True Labels')\n",
    "plt.ylabel('Predicted Labels')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81d710cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_name = 'dense_4' \n",
    "intermediate_layer_model = Model(inputs=baseline_model.input,\n",
    "                                 outputs=baseline_model.get_layer(layer_name).output)\n",
    "\n",
    "# Select some data to pass through the model\n",
    "data_samples, labels = next(train_generator)\n",
    "\n",
    "# Get the output of the layer\n",
    "activations = intermediate_layer_model.predict(data_samples)\n",
    "\n",
    "# Now plot the activations of the first neuron as an example\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.plot(activations[16], label=f'Activations of first neuron in {layer_name}')\n",
    "plt.title('Activations')\n",
    "plt.xlabel('Activation Index')\n",
    "plt.ylabel('Activation Value')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77a65033",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the CNN model\n",
    "cnn_model = Sequential()\n",
    "\n",
    "# Convolutional layer block 1 with Batch Normalization\n",
    "cnn_model.add(Conv2D(filters=32, kernel_size=(3, 3), input_shape=(512, 512, 3), padding='same'))\n",
    "cnn_model.add(BatchNormalization())\n",
    "cnn_model.add(Activation('leaky_relu'))\n",
    "cnn_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Convolutional layer block 2 with more filters\n",
    "cnn_model.add(Conv2D(filters=64, kernel_size=(3, 3), padding='same'))\n",
    "cnn_model.add(BatchNormalization())\n",
    "cnn_model.add(Activation('leaky_relu'))\n",
    "cnn_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Convolutional layer block 3 with increased depth\n",
    "cnn_model.add(Conv2D(filters=256, kernel_size=(3, 3), padding='same'))\n",
    "cnn_model.add(BatchNormalization())\n",
    "cnn_model.add(Activation('leaky_relu'))\n",
    "cnn_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Flatten before passing to the dense layers\n",
    "cnn_model.add(Flatten())\n",
    "\n",
    "# Dense layer with regularization\n",
    "cnn_model.add(Dense(512, activation='leaky_relu', kernel_regularizer=regularizers.l2(0.01)))\n",
    "cnn_model.add(Dropout(0.5))\n",
    "cnn_model.add(Dense(256, activation='leaky_relu', kernel_regularizer=regularizers.l2(0.01)))\n",
    "cnn_model.add(Dropout(0.5))\n",
    "\n",
    "# Output layer\n",
    "cnn_model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "cnn_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "cnn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c360e286",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping_cnn = EarlyStopping(monitor='val_loss', patience=10, verbose=1, mode='min', restore_best_weights=True)\n",
    "\n",
    "class_weights_cnn = {0 : 1.9, 1 : 1}\n",
    "\n",
    "history_cnn = cnn_model.fit(\n",
    "    train_generator,\n",
    "    epochs=60,\n",
    "    batch_size=64,\n",
    "    validation_data=validation_generator,\n",
    "    callbacks=[early_stopping, model_checkpoint],\n",
    "    class_weight=class_weights_cnn,\n",
    "    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "518619af",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_probabilities_cnn = cnn_model.predict(test_datagen)\n",
    "predicted_labels_cnn = predicted_probabilities_cnn > 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69df48ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_report = classification_report(true_labels, predicted_labels_cnn, target_names=['Normal', 'Pneumonia'])\n",
    "print(cnn_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7067d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_mat = confusion_matrix(true_labels_vanilla, predicted_labels_cnn)\n",
    "sns.heatmap(cnn_mat.T, square=True, annot=True, cbar=False, cmap='viridis',\n",
    "            xticklabels=['Negative', 'Positive'],\n",
    "            yticklabels=['Negative', 'Positive'])\n",
    "plt.xlabel('True Labels')\n",
    "plt.ylabel('Predicted Labels')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b11e0e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_outputs = [layer.output for layer in cnn_model.layers[:8]]\n",
    "\n",
    "# Rather then a model with a single output, we are going to make a model to display the feature maps\n",
    "activation_model = models.Model(inputs=cnn_model.input, outputs=layer_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29d27311",
   "metadata": {},
   "outputs": [],
   "source": [
    "activations = activation_model.predict(img_tensor)\n",
    "\n",
    "first_layer_activation = activations[0]\n",
    "print(first_layer_activation.shape)\n",
    "\n",
    "# We slice the third channel and preview the results\n",
    "plt.matshow(first_layer_activation[0, :, :, 31], cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10e2516d",
   "metadata": {},
   "outputs": [],
   "source": [
    "activations = activation_model.predict(img_tensor)\n",
    "\n",
    "first_layer_activation = activations[0]\n",
    "print(first_layer_activation.shape)\n",
    "\n",
    "plt.matshow(first_layer_activation[0, :, :, 30], cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0fac014",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(8, 4, figsize=(12,24))\n",
    "for i in range(32):\n",
    "    row = i//4\n",
    "    column = i%4\n",
    "    ax = axes[row, column]\n",
    "    first_layer_activation = activations[0]\n",
    "    ax.matshow(first_layer_activation[0, :, :, i], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21924a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2,4, figsize=(12,8))\n",
    "\n",
    "layer_names = []\n",
    "for layer in cnn_model.layers[:8]:\n",
    "    layer_names.append(layer.name)\n",
    "\n",
    "for i in range(8):\n",
    "    row = i//4\n",
    "    column = i%4\n",
    "    ax = axes[row, column]\n",
    "    cur_layer = activations[i]\n",
    "    ax.matshow(cur_layer[0, :, :, 29], cmap='gray')\n",
    "    ax.xaxis.set_ticks_position('bottom')\n",
    "    ax.set_title(layer_names[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bdd166f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mobilenet_train_generator = datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(224, 224),  # The target size for your images\n",
    "    batch_size=64,  # The batch size\n",
    "    class_mode='binary',\n",
    "    subset='training',  # Set the subset of data to training\n",
    "    shuffle=True)\n",
    "\n",
    "mobilenet_validation_generator = datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=64,\n",
    "    class_mode='binary',\n",
    "    subset='validation',  # Set the subset of data to validation\n",
    "    shuffle=True)\n",
    "\n",
    "mobilenet_test_generator = ImageDataGenerator(rescale=1./255).flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(224,224),\n",
    "    batch_size=64, class_mode='binary', shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "766db47a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mobilenet = MobileNetV2(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "mobilenet.trainable = False  # Freeze the convolutional base\n",
    "\n",
    "# Create a new model on top\n",
    "transfer_model = Sequential()\n",
    "\n",
    "transfer_model.add(mobilenet)\n",
    "transfer_model.add(GlobalAveragePooling2D())\n",
    "transfer_model.add(Dense(512, activation='relu'))\n",
    "transfer_model.add(Dropout(0.5))\n",
    "transfer_model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model\n",
    "transfer_model.compile(optimizer=optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=1e-4),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "transfer_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cbded02",
   "metadata": {},
   "outputs": [],
   "source": [
    "transfer_early_stopping = EarlyStopping(monitor='val_loss', patience=7, verbose=1, mode='min', restore_best_weights=True)\n",
    "\n",
    "transfer_model_checkpoint = ModelCheckpoint(filepath='best_model.h5', monitor='val_loss', save_best_only=True, verbose=1, mode='min')\n",
    "\n",
    "transfer_class_weights = {0 : 2, 1 : 1}\n",
    "\n",
    "transfer_history = transfer_model.fit(\n",
    "    mobilenet_train_generator,\n",
    "    steps_per_epoch=mobilenet_train_generator.n // mobilenet_train_generator.batch_size,\n",
    "    epochs=10,\n",
    "    validation_data=mobilenet_validation_generator,\n",
    "    validation_steps=mobilenet_validation_generator.n // mobilenet_validation_generator.batch_size,\n",
    "    callbacks=[transfer_early_stopping, transfer_model_checkpoint],\n",
    "    class_weight=transfer_class_weights,\n",
    "    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d13231ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_probabilities_transfer = transfer_model.predict(mobilenet_test_generator)\n",
    "predicted_labels_transfer = predicted_probabilities_transfer > 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6316f129",
   "metadata": {},
   "outputs": [],
   "source": [
    "mobilenet_true_labels = mobilenet_test_generator.classes\n",
    "transfer_report = classification_report(mobilenet_true_labels, predicted_labels_transfer, target_names=['Normal', 'Pneumonia'])\n",
    "print(transfer_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72e28ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "transfer_train_loss = transfer_history.history['loss']\n",
    "transfer_val_loss = transfer_history.history['val_loss']\n",
    "\n",
    "epoch_count = range(1, len(transfer_train_loss) + 1)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(epoch_count, transfer_train_loss)\n",
    "plt.plot(epoch_count, transfer_val_loss)\n",
    "plt.legend(['Training Loss', 'Validation Loss'])\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss Over Epochs')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb1e1baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "transfer_mat = confusion_matrix(true_labels_vanilla, predicted_labels_transfer)\n",
    "sns.heatmap(transfer_mat.T, square=True, annot=True, fmt='d', cbar=False, cmap='viridis',\n",
    "            xticklabels=['Negative', 'Positive'],\n",
    "            yticklabels=['Negative', 'Positive'])\n",
    "plt.xlabel('True Labels')\n",
    "plt.ylabel('Predicted Labels')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee178049",
   "metadata": {},
   "source": [
    "## Final Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22ad8b3e",
   "metadata": {},
   "source": [
    "# Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ce082fa",
   "metadata": {},
   "source": [
    "## Next Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d3373c1",
   "metadata": {},
   "source": [
    "## Contact Information"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d512aec",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
